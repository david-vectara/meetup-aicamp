{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622b357b-5de3-4387-978c-55b2bce3b2f5",
   "metadata": {},
   "source": [
    "# Example Queries\n",
    "\n",
    "We'll now demonstrate the power of Vectara using a curated corpus:\n",
    "\n",
    "* Search for authors semantically and using custom dimensions\n",
    "* Using Filter Attributes (online / physical)\n",
    "* Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771898ad-5a56-4c24-a40f-87cb0e82bb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:34:44 +1000:Factory                             INFO:initializing builder\n",
      "14:34:44 +1000:Factory                             INFO:Factory will load configuration from home directory\n",
      "14:34:44 +1000:HomeConfigLoader                    INFO:Loading configuration from users home directory [C:\\Users\\david]\n",
      "14:34:44 +1000:HomeConfigLoader                    INFO:Loading default configuration [default]\n",
      "14:34:44 +1000:HomeConfigLoader                    INFO:Parsing config\n",
      "14:34:44 +1000:root                                INFO:We are processing authentication type [OAuth2]\n",
      "14:34:44 +1000:OAuthUtil                           INFO:Using provided OAuth2 URL [https://vectara-prod-1623270172.auth.us-west-2.amazoncognito.com/oauth2/token]\n",
      "14:34:44 +1000:OAuthUtil                           INFO:OAuth2 URL is [https://vectara-prod-1623270172.auth.us-west-2.amazoncognito.com/oauth2/token]\n",
      "14:34:44 +1000:root                                INFO:initializing Client\n",
      "14:34:44 +1000:OAuthUtil                           INFO:Current timestamp 2024-05-15 14:34:44.018485\n",
      "14:34:44 +1000:OAuthUtil                           INFO:First time requesting token, authenticating\n",
      "14:34:45 +1000:OAuthUtil                           INFO:Received OAuth token, will expire [05/15/2024, 15:34:45]\n",
      "14:34:45 +1000:OAuthUtil                           INFO:Already authenticated with non-expired token, expiry is [1715751285]\n",
      "14:34:45 +1000:RequestUtil                         INFO:URL for operation list-corpora is: https://api.vectara.io/v1/list-corpora\n",
      "14:34:46 +1000:CorpusManager                       INFO:Checking corpus with name [AICamp Sessions 2]\n",
      "14:34:46 +1000:CorpusManager                       INFO:Our corpus id is [749]\n"
     ]
    }
   ],
   "source": [
    "from vectara_client.core import Factory\n",
    "from vectara_client.admin import CorpusBuilder\n",
    "from vectara_client.util import render_markdown\n",
    "from IPython.display import display, Markdown\n",
    "import logging\n",
    "import json\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s:%(name)-35s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%H:%M:%S %z')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "client = Factory().build()\n",
    "manager = client.corpus_manager\n",
    "\n",
    "corpus_id = manager.find_corpus_by_name(\"AICamp Sessions 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52891a7e-ec7b-4ee8-bf14-77b3cea645e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = client.query_service\n",
    "\n",
    "def render_response(query, response, show_search_results=True):\n",
    "    rendered = render_markdown(query, response, show_search_results=show_search_results)\n",
    "    display(Markdown(rendered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec824de-995d-44d1-97a0-0f4428c56bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:41:28 +1000:OAuthUtil                           INFO:Current timestamp 2024-05-15 14:41:28.367861\n",
      "14:41:28 +1000:OAuthUtil                           INFO:Expiry            2024-05-15 15:34:45\n",
      "14:41:28 +1000:OAuthUtil                           INFO:Already authenticated with non-expired token, expiry is [1715751285]\n",
      "14:41:28 +1000:RequestUtil                         INFO:URL for operation query is: https://api.vectara.io/v1/query\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Query: What were the topics discussed at the meetup\n",
       "\n",
       "The meetup covered a range of topics in the field of large language models and AI application. Federico Bianchi, a post-doctoral researcher at Stanford University, discussed the current state and future prospects of large language models, touching on his experience with building large Vision-Language models, model understanding, and addressing fairness and bias [1][2]. Additionally, there was a workshop focused on data and AI observability, with topics like detecting data drift, measuring model drift, monitoring model performance, validating data quality, measuring bias & fairness, and explaining models. This session was approachable for most skill levels and did not require specific knowledge, although familiarity with machine learning and Python was beneficial [3][4][5].\n",
       "\n",
       " 1. <b>What were the topics discussed at the meetup</b> Title:LLMs: Beyond Proofs of Concept\n",
       "When: 2023/05/04\n",
       "Federico Bianchi is a post-doctoral researcher at Stanford University, with experience in building large Vision-Language models (e.g., FashionCLIP), model understanding (e.g., Limitations of Vision-Language Models) and fairness and bias (e.g., Bias in Text-to-Image, EvalRS). He discusses where the field of large language models is today and what we can expect to see in terms of business value, once the hype dies down. *score: 1.8671196, doc-id: 293038498-0*\n",
       " 2. What were the topics discussed at the meetup Title:LLMs: Beyond Proofs of Concept\n",
       "When: 2023/05/04\n",
       "Federico Bianchi is a post-doctoral researcher at Stanford University, with experience in building large Vision-Language models (e.g., FashionCLIP), model understanding (e.g., Limitations of Vision-Language Models) and fairness and bias (e.g., Bias in Text-to-Image, EvalRS). <b>He discusses where the field of large language models is today and what we can expect to see in terms of business value, once the hype dies down.</b> Speaker 1: Federico Bianchi@Stanford University - Post-doctoral researcher at Stanford University, with experience in building large Vision-Language models, model understanding and fairness and bias. Speaker 2: Hugo Bowne-Anderson@Outerbounds - Head of Developer Relations at Outerbounds. *score: 0.8266891, doc-id: 293038498-0*\n",
       " 3. Implementing Data and AI Observability The session covered how to build reliable pipelines, trustworthy data, and responsible AI applications. <b>Topics included detecting data drift, measuring model drift, monitoring model performance, data quality validation, measuring bias & fairness, and model explainability.</b> The workshop was designed to be approachable for most skill levels. Familiarity with machine learning and Python was useful, but not required. *score: 0.7549026, doc-id: 293478387-0*\n",
       " 4. Implementing Data and AI Observability <b>The session covered how to build reliable pipelines, trustworthy data, and responsible AI applications.</b> Topics included detecting data drift, measuring model drift, monitoring model performance, data quality validation, measuring bias & fairness, and model explainability. The workshop was designed to be approachable for most skill levels. *score: 0.75180715, doc-id: 293478387-0*\n",
       " 5. The session covered how to build reliable pipelines, trustworthy data, and responsible AI applications. Topics included detecting data drift, measuring model drift, monitoring model performance, data quality validation, measuring bias & fairness, and model explainability. <b>The workshop was designed to be approachable for most skill levels.</b> Familiarity with machine learning and Python was useful, but not required. *score: 0.73147094, doc-id: 293478387-0*\n",
       " 6. He discusses where the field of large language models is today and what we can expect to see in terms of business value, once the hype dies down. Speaker 1: Federico Bianchi@Stanford University - Post-doctoral researcher at Stanford University, with experience in building large Vision-Language models, model understanding and fairness and bias. <b>Speaker 2: Hugo Bowne-Anderson@Outerbounds - Head of Developer Relations at Outerbounds.</b> *score: 0.7194697, doc-id: 293038498-0*\n",
       " 7. Title:LLMs: Beyond Proofs of Concept\n",
       "When: 2023/05/04\n",
       "Federico Bianchi is a post-doctoral researcher at Stanford University, with experience in building large Vision-Language models (e.g., FashionCLIP), model understanding (e.g., Limitations of Vision-Language Models) and fairness and bias (e.g., Bias in Text-to-Image, EvalRS). He discusses where the field of large language models is today and what we can expect to see in terms of business value, once the hype dies down. <b>Speaker 1: Federico Bianchi@Stanford University - Post-doctoral researcher at Stanford University, with experience in building large Vision-Language models, model understanding and fairness and bias.</b> Speaker 2: Hugo Bowne-Anderson@Outerbounds - Head of Developer Relations at Outerbounds. *score: 0.66426575, doc-id: 293038498-0*\n",
       " 8. What were the topics discussed at the meetup <b>Title:LLMs: Beyond Proofs of Concept\n",
       "When: 2023/05/04\n",
       "Federico Bianchi is a post-doctoral researcher at Stanford University, with experience in building large Vision-Language models (e.g., FashionCLIP), model understanding (e.g., Limitations of Vision-Language Models) and fairness and bias (e.g., Bias in Text-to-Image, EvalRS).</b> He discusses where the field of large language models is today and what we can expect to see in terms of business value, once the hype dies down. Speaker 1: Federico Bianchi@Stanford University - Post-doctoral researcher at Stanford University, with experience in building large Vision-Language models, model understanding and fairness and bias. *score: 0.63718915, doc-id: 293038498-0*\n",
       " 9. Topics included detecting data drift, measuring model drift, monitoring model performance, data quality validation, measuring bias & fairness, and model explainability. The workshop was designed to be approachable for most skill levels. <b>Familiarity with machine learning and Python was useful, but not required.</b> *score: 0.5847223, doc-id: 293478387-0*\n",
       " 10. <b>Implementing Data and AI Observability</b> The session covered how to build reliable pipelines, trustworthy data, and responsible AI applications. Topics included detecting data drift, measuring model drift, monitoring model performance, data quality validation, measuring bias & fairness, and model explainability. *score: 0.57043797, doc-id: 293478387-0*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "query = \"What were the topics discussed at the meetup\"\n",
    "response = qs.query(query, corpus_id, summary=True, summarizer=\"vectara-summary-ext-v1.3.0\", metadata = \"((doc.event_month = '05') AND (doc.event_year = '2023'))\")\n",
    "render_response(query, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "215a24f3-7551-4d33-8419-625f304cb5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:42:56 +1000:OAuthUtil                           INFO:Current timestamp 2024-05-15 14:42:56.115204\n",
      "14:42:56 +1000:OAuthUtil                           INFO:Expiry            2024-05-15 15:34:45\n",
      "14:42:56 +1000:OAuthUtil                           INFO:Already authenticated with non-expired token, expiry is [1715751285]\n",
      "14:42:56 +1000:RequestUtil                         INFO:URL for operation query is: https://api.vectara.io/v1/query\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Query: What speeches has Federico Bianchi been involved in?\n",
       "\n",
       "Federico Bianchi, a post-doctoral researcher at Stanford University, has been involved in speeches at events such as the meetup titled \"LLMs: Beyond Proofs of Concept\". In these speeches, he discusses topics like the current state and future expectations of large language models from a business value perspective once the ongoing hype subsides. His research experience includes building large Vision-Language models, model understanding, and addressing fairness and bias. Notable works he refers to in his talks include \"FashionCLIP\", \"Limitations of Vision-Language Models\", \"Bias in Text-to-Image\", and \"EvalRS\" [1][2][3][4][5].\n",
       "\n",
       " 1. Title:LLMs: Beyond Proofs of Concept\n",
       "When: 2023/05/04\n",
       "Federico Bianchi is a post-doctoral researcher at Stanford University, with experience in building large Vision-Language models (e.g., FashionCLIP), model understanding (e.g., Limitations of Vision-Language Models) and fairness and bias (e.g., Bias in Text-to-Image, EvalRS). He discusses where the field of large language models is today and what we can expect to see in terms of business value, once the hype dies down. <b>Speaker 1: Federico Bianchi@Stanford University - Post-doctoral researcher at Stanford University, with experience in building large Vision-Language models, model understanding and fairness and bias.</b> Speaker 2: Hugo Bowne-Anderson@Outerbounds - Head of Developer Relations at Outerbounds. *score: 1.0950897, doc-id: 293038498-0*\n",
       " 2. What were the topics discussed at the meetup <b>Title:LLMs: Beyond Proofs of Concept\n",
       "When: 2023/05/04\n",
       "Federico Bianchi is a post-doctoral researcher at Stanford University, with experience in building large Vision-Language models (e.g., FashionCLIP), model understanding (e.g., Limitations of Vision-Language Models) and fairness and bias (e.g., Bias in Text-to-Image, EvalRS).</b> He discusses where the field of large language models is today and what we can expect to see in terms of business value, once the hype dies down. Speaker 1: Federico Bianchi@Stanford University - Post-doctoral researcher at Stanford University, with experience in building large Vision-Language models, model understanding and fairness and bias. *score: 0.9577244, doc-id: 293038498-0*\n",
       " 3. <b>What were the topics discussed at the meetup</b> Title:LLMs: Beyond Proofs of Concept\n",
       "When: 2023/05/04\n",
       "Federico Bianchi is a post-doctoral researcher at Stanford University, with experience in building large Vision-Language models (e.g., FashionCLIP), model understanding (e.g., Limitations of Vision-Language Models) and fairness and bias (e.g., Bias in Text-to-Image, EvalRS). He discusses where the field of large language models is today and what we can expect to see in terms of business value, once the hype dies down. *score: 0.7525915, doc-id: 293038498-0*\n",
       " 4. What were the topics discussed at the meetup Title:LLMs: Beyond Proofs of Concept\n",
       "When: 2023/05/04\n",
       "Federico Bianchi is a post-doctoral researcher at Stanford University, with experience in building large Vision-Language models (e.g., FashionCLIP), model understanding (e.g., Limitations of Vision-Language Models) and fairness and bias (e.g., Bias in Text-to-Image, EvalRS). <b>He discusses where the field of large language models is today and what we can expect to see in terms of business value, once the hype dies down.</b> Speaker 1: Federico Bianchi@Stanford University - Post-doctoral researcher at Stanford University, with experience in building large Vision-Language models, model understanding and fairness and bias. Speaker 2: Hugo Bowne-Anderson@Outerbounds - Head of Developer Relations at Outerbounds. *score: 0.75222516, doc-id: 293038498-0*\n",
       " 5. He discusses where the field of large language models is today and what we can expect to see in terms of business value, once the hype dies down. Speaker 1: Federico Bianchi@Stanford University - Post-doctoral researcher at Stanford University, with experience in building large Vision-Language models, model understanding and fairness and bias. <b>Speaker 2: Hugo Bowne-Anderson@Outerbounds - Head of Developer Relations at Outerbounds.</b> *score: 0.62515867, doc-id: 293038498-0*\n",
       " 6. Implementing Data and AI Observability <b>The session covered how to build reliable pipelines, trustworthy data, and responsible AI applications.</b> Topics included detecting data drift, measuring model drift, monitoring model performance, data quality validation, measuring bias & fairness, and model explainability. The workshop was designed to be approachable for most skill levels. *score: 0.5871126, doc-id: 293478387-0*\n",
       " 7. <b>Implementing Data and AI Observability</b> The session covered how to build reliable pipelines, trustworthy data, and responsible AI applications. Topics included detecting data drift, measuring model drift, monitoring model performance, data quality validation, measuring bias & fairness, and model explainability. *score: 0.5653109, doc-id: 293478387-0*\n",
       " 8. Implementing Data and AI Observability The session covered how to build reliable pipelines, trustworthy data, and responsible AI applications. <b>Topics included detecting data drift, measuring model drift, monitoring model performance, data quality validation, measuring bias & fairness, and model explainability.</b> The workshop was designed to be approachable for most skill levels. Familiarity with machine learning and Python was useful, but not required. *score: 0.55862194, doc-id: 293478387-0*\n",
       " 9. The session covered how to build reliable pipelines, trustworthy data, and responsible AI applications. Topics included detecting data drift, measuring model drift, monitoring model performance, data quality validation, measuring bias & fairness, and model explainability. <b>The workshop was designed to be approachable for most skill levels.</b> Familiarity with machine learning and Python was useful, but not required. *score: 0.5496897, doc-id: 293478387-0*\n",
       " 10. Topics included detecting data drift, measuring model drift, monitoring model performance, data quality validation, measuring bias & fairness, and model explainability. The workshop was designed to be approachable for most skill levels. <b>Familiarity with machine learning and Python was useful, but not required.</b> *score: 0.527577, doc-id: 293478387-0*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What speeches has Federico Bianchi been involved in?\"\n",
    "response = qs.query(query, corpus_id, summary=True, summarizer=\"vectara-summary-ext-v1.3.0\", metadata = \"((doc.event_month = '05') AND (doc.event_year = '2023'))\")\n",
    "render_response(query, response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
